{
  "id": "qwen-vl-image-edit-example",
  "revision": 0,
  "last_node_id": 115,
  "last_link_id": 219,
  "nodes": [
    {
      "id": 1,
      "type": "Note",
      "pos": [
        -400,
        -200
      ],
      "size": [
        400,
        150
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": [
        "IMPROVED QWEN2.5-VL WORKFLOW\n\nThis workflow uses the new proper Qwen2.5-VL nodes with real vision processing:\n- QwenVLLoader: Loads actual Qwen2.5-VL model\n- QwenVLTextEncoder: Real multimodal encoding\n- Exact system prompts from DiffSynth-Studio\n\nRequires: pip install transformers"
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 37,
      "type": "UNETLoader",
      "pos": [
        20,
        20
      ],
      "size": [
        330,
        90
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [
            196
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "UNETLoader",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": [
        "qwen_image_edit_fp8_e4m3fn.safetensors",
        "fp8_e4m3fn"
      ]
    },
    {
      "id": 39,
      "type": "VAELoader",
      "pos": [
        20,
        340
      ],
      "size": [
        330,
        60
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "slot_index": 0,
          "links": [
            134,
            136,
            167
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "VAELoader",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": [
        "qwen_image_vae.safetensors"
      ]
    },
    {
      "id": 66,
      "type": "ModelSamplingAuraFlow",
      "pos": [
        860,
        -145
      ],
      "size": [
        300,
        58
      ],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 217
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            154
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "ModelSamplingAuraFlow",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": [
        3.5
      ]
    },
    {
      "id": 73,
      "type": "LoraLoaderModelOnly",
      "pos": [
        395,
        50
      ],
      "size": [
        270,
        82
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 196
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            170,
            217
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "LoraLoaderModelOnly",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": [
        "Qwen-Image-Lightning-4steps-V1.0.safetensors",
        1
      ]
    },
    {
      "id": 76,
      "type": "LoadImage",
      "pos": [
        20,
        460
      ],
      "size": [
        280,
        320
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            185,
            194,
            200
          ]
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": [
            201
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "LoadImage",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": [
        "view.png",
        "image"
      ]
    },
    {
      "id": 77,
      "type": "VAEEncode",
      "pos": [
        620,
        680
      ],
      "size": [
        140,
        46
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "name": "pixels",
          "type": "IMAGE",
          "link": 202
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 136
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            209
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "VAEEncode",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": []
    },
    {
      "id": 80,
      "type": "ConditioningZeroOut",
      "pos": [
        600,
        580
      ],
      "size": [
        200,
        26
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "conditioning",
          "type": "CONDITIONING",
          "link": 212
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            208
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "ConditioningZeroOut",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": []
    },
    {
      "id": 81,
      "type": "CFGNorm",
      "pos": [
        870,
        15
      ],
      "size": [
        270,
        58
      ],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 154
        }
      ],
      "outputs": [
        {
          "name": "patched_model",
          "type": "MODEL",
          "links": [
            206
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "CFGNorm",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": [
        1
      ]
    },
    {
      "id": 84,
      "type": "VAEDecodeTiled",
      "pos": [
        1225,
        760
      ],
      "size": [
        210,
        150
      ],
      "flags": {},
      "order": 14,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 210
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 167
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            205
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "VAEDecodeTiled",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": [
        512,
        64,
        64,
        8
      ]
    },
    {
      "id": 106,
      "type": "ImageResizeKJv2",
      "pos": [
        130,
        840
      ],
      "size": [
        270,
        340
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "image",
          "type": "IMAGE",
          "link": 200
        },
        {
          "name": "mask",
          "shape": 7,
          "type": "MASK",
          "link": 201
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            202
          ]
        },
        {
          "name": "width",
          "type": "INT",
          "links": null
        },
        {
          "name": "height",
          "type": "INT",
          "links": null
        },
        {
          "name": "mask",
          "type": "MASK",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfyui-kjnodes",
        "ver": "1.1.4",
        "Node name for S&R": "ImageResizeKJv2",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": [
        1328,
        1328,
        "lanczos",
        "pad",
        "0, 0, 0",
        "center",
        2,
        "cpu"
      ]
    },
    {
      "id": 108,
      "type": "SaveImage",
      "pos": [
        1435,
        155
      ],
      "size": [
        270,
        270
      ],
      "flags": {},
      "order": 15,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 205
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "SaveImage",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": [
        "qwen_vl_edit"
      ]
    },
    {
      "id": 109,
      "type": "KSampler",
      "pos": [
        874.0758666992188,
        114.94629669189453
      ],
      "size": [
        300,
        556
      ],
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 206
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 213
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 208
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 209
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            210
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "KSampler",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": [
        668523011998122,
        "randomize",
        4,
        1,
        "euler",
        "simple",
        1
      ]
    },
    {
      "id": 111,
      "type": "QwenVLTextEncoder",
      "pos": [
        410,
        250
      ],
      "size": [
        400,
        280
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "qwen_model",
          "type": "QWEN_VL_MODEL",
          "link": 219
        },
        {
          "name": "edit_image",
          "shape": 7,
          "type": "IMAGE",
          "link": 194
        }
      ],
      "outputs": [
        {
          "name": "conditioning",
          "type": "CONDITIONING",
          "links": [
            212,
            213
          ]
        },
        {
          "name": "vision_features",
          "type": "LATENT",
          "links": null
        }
      ],
      "title": "Qwen2.5-VL Text Encoder (NEW)",
      "properties": {
        "aux_id": "fblissjr/ComfyUI-QwenImageWanBridge",
        "ver": "2439687525b8950a5d3ed63042f6e5b96adc80b0",
        "Node name for S&R": "QwenVLTextEncoder",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": [
        "Transform the white coffee mug to float 20px above the wooden table's surface while maintaining its size and orientation, preserving all other elements in the kitchen scene.",
        "image_edit",
        true
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 112,
      "type": "Note",
      "pos": [
        850,
        760
      ],
      "size": [
        350,
        200
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": [
        "KEY IMPROVEMENTS:\n\n1. QwenVLLoader loads actual Qwen2.5-VL model\n2. QwenVLTextEncoder does real vision processing\n3. Vision tokens actually work now!\n4. Exact system prompts from DiffSynth-Studio\n5. Proper multimodal fusion\n\nThe old CLIPLoader approach is replaced with proper transformers integration."
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 115,
      "type": "QwenVLLoader",
      "pos": [
        29.912580490112305,
        176.76263427734375
      ],
      "size": [
        270,
        106
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "model",
          "type": "QWEN_VL_MODEL",
          "links": [
            219
          ]
        }
      ],
      "properties": {
        "aux_id": "fblissjr/ComfyUI-QwenImageWanBridge",
        "ver": "2439687525b8950a5d3ed63042f6e5b96adc80b0",
        "Node name for S&R": "QwenVLLoader",
        "ue_properties": {
          "widget_ue_connectable": {
            "model_name": true,
            "precision": true,
            "device": true
          },
          "version": "7.0.1"
        }
      },
      "widgets_values": [
        "qwen_2.5_vl_7b.safetensors",
        "fp16",
        "cuda"
      ]
    }
  ],
  "links": [
    [
      134,
      39,
      0,
      77,
      1,
      "VAE"
    ],
    [
      136,
      39,
      0,
      77,
      1,
      "VAE"
    ],
    [
      154,
      66,
      0,
      81,
      0,
      "MODEL"
    ],
    [
      162,
      88,
      0,
      86,
      0,
      "MODEL"
    ],
    [
      167,
      39,
      0,
      84,
      1,
      "VAE"
    ],
    [
      169,
      86,
      0,
      87,
      0,
      "MODEL"
    ],
    [
      170,
      73,
      0,
      88,
      0,
      "MODEL"
    ],
    [
      185,
      76,
      0,
      79,
      0,
      "IMAGE"
    ],
    [
      194,
      76,
      0,
      111,
      1,
      "IMAGE"
    ],
    [
      196,
      37,
      0,
      73,
      0,
      "MODEL"
    ],
    [
      200,
      76,
      0,
      106,
      0,
      "IMAGE"
    ],
    [
      201,
      76,
      1,
      106,
      1,
      "MASK"
    ],
    [
      202,
      106,
      0,
      77,
      0,
      "IMAGE"
    ],
    [
      204,
      87,
      0,
      66,
      0,
      "MODEL"
    ],
    [
      205,
      84,
      0,
      108,
      0,
      "IMAGE"
    ],
    [
      206,
      81,
      0,
      109,
      0,
      "MODEL"
    ],
    [
      208,
      80,
      0,
      109,
      2,
      "CONDITIONING"
    ],
    [
      209,
      77,
      0,
      109,
      3,
      "LATENT"
    ],
    [
      210,
      109,
      0,
      84,
      0,
      "LATENT"
    ],
    [
      212,
      111,
      0,
      80,
      0,
      "CONDITIONING"
    ],
    [
      213,
      111,
      0,
      109,
      1,
      "CONDITIONING"
    ],
    [
      217,
      73,
      0,
      66,
      0,
      "MODEL"
    ],
    [
      219,
      115,
      0,
      111,
      0,
      "QWEN_VL_MODEL"
    ]
  ],
  "groups": [
    {
      "id": 1,
      "title": "Step 1 - Load Models (IMPROVED)",
      "bounding": [
        10,
        -50,
        370,
        480
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 2,
      "title": "Step 2 - Image Preprocessing",
      "bounding": [
        10,
        800,
        400,
        400
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 3,
      "title": "Step 3 - Multimodal Encoding (NEW)",
      "bounding": [
        380,
        160,
        450,
        470
      ],
      "color": "#a1309b",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 4,
      "title": "Step 4 - Generation Pipeline",
      "bounding": [
        850,
        -400,
        600,
        1100
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 1.0764329258859686,
      "offset": [
        698.0757143334406,
        279.76412109968516
      ]
    },
    "ue_links": [],
    "links_added_by_ue": [],
    "frontendVersion": "1.25.9",
    "VHS_latentpreview": true,
    "VHS_latentpreviewrate": 0,
    "VHS_MetadataImage": true,
    "VHS_KeepIntermediate": true
  },
  "version": 0.4
}