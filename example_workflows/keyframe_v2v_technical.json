{
  "last_node_id": 15,
  "last_link_id": 20,
  "nodes": [
    {
      "id": 1,
      "type": "LoadImage",
      "pos": [50, 100],
      "size": {"0": 315, "1": 100},
      "flags": {},
      "order": 0,
      "mode": 0,
      "outputs": [
        {"name": "IMAGE", "type": "IMAGE", "links": [1, 2]},
        {"name": "MASK", "type": "MASK", "links": null}
      ],
      "properties": {},
      "widgets_values": ["example.png", "image"]
    },
    {
      "id": 2,
      "type": "QwenVLCLIPLoader",
      "pos": [50, 250],
      "size": {"0": 315, "1": 100},
      "flags": {},
      "order": 1,
      "mode": 0,
      "outputs": [
        {"name": "CLIP", "type": "CLIP", "links": [3]}
      ],
      "properties": {},
      "widgets_values": ["Qwen2.5-VL-7B.safetensors"]
    },
    {
      "id": 3,
      "type": "QwenVLTextEncoder",
      "pos": [400, 250],
      "size": {"0": 400, "1": 200},
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [
        {"name": "clip", "type": "CLIP", "link": 3},
        {"name": "edit_image", "type": "IMAGE", "link": 1}
      ],
      "outputs": [
        {"name": "CONDITIONING", "type": "CONDITIONING", "links": [4]}
      ],
      "properties": {},
      "widgets_values": ["Change the person's shirt to red", "image_edit", true, 64]
    },
    {
      "id": 4,
      "type": "CheckpointLoaderSimple",
      "pos": [50, 500],
      "size": {"0": 315, "1": 100},
      "flags": {},
      "order": 3,
      "mode": 0,
      "outputs": [
        {"name": "MODEL", "type": "MODEL", "links": [5]},
        {"name": "CLIP", "type": "CLIP", "links": null},
        {"name": "VAE", "type": "VAE", "links": [6, 10]}
      ],
      "properties": {},
      "widgets_values": ["Qwen-Image-Edit.safetensors"]
    },
    {
      "id": 5,
      "type": "VAEEncode",
      "pos": [400, 500],
      "size": {"0": 315, "1": 100},
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [
        {"name": "pixels", "type": "IMAGE", "link": 2},
        {"name": "vae", "type": "VAE", "link": 6}
      ],
      "outputs": [
        {"name": "LATENT", "type": "LATENT", "links": [7, 12]}
      ],
      "properties": {}
    },
    {
      "id": 6,
      "type": "KSampler",
      "pos": [850, 250],
      "size": {"0": 315, "1": 262},
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [
        {"name": "model", "type": "MODEL", "link": 5},
        {"name": "positive", "type": "CONDITIONING", "link": 4},
        {"name": "negative", "type": "CONDITIONING", "link": null},
        {"name": "latent_image", "type": "LATENT", "link": 7}
      ],
      "outputs": [
        {"name": "LATENT", "type": "LATENT", "links": [8]}
      ],
      "properties": {},
      "widgets_values": [42, "randomize", 15, 5.0, "dpmpp_2m", "karras", 0.35]
    },
    {
      "id": 7,
      "type": "VAEDecode",
      "pos": [1200, 250],
      "size": {"0": 315, "1": 100},
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {"name": "samples", "type": "LATENT", "link": 8},
        {"name": "vae", "type": "VAE", "link": 10}
      ],
      "outputs": [
        {"name": "IMAGE", "type": "IMAGE", "links": [9, 11]}
      ],
      "properties": {}
    },
    {
      "id": 8,
      "type": "MinimalKeyframeV2V",
      "pos": [850, 600],
      "size": {"0": 400, "1": 350},
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {"name": "video_latents", "type": "LATENT", "link": 12},
        {"name": "edited_frames", "type": "IMAGE", "link": 9}
      ],
      "outputs": [
        {"name": "output_latents", "type": "LATENT", "links": [13, 15]},
        {"name": "denoise_schedule", "type": "FLOAT_ARRAY", "links": [16]},
        {"name": "technical_log", "type": "STRING", "links": [14]}
      ],
      "properties": {},
      "widgets_values": [
        "0",
        0.35,
        0.10,
        5.0,
        20,
        "DPM-Solver++",
        "karras",
        "stepped",
        10
      ]
    },
    {
      "id": 9,
      "type": "VAEDecode",
      "pos": [1300, 600],
      "size": {"0": 315, "1": 100},
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {"name": "samples", "type": "LATENT", "link": 13},
        {"name": "vae", "type": "VAE", "link": null}
      ],
      "outputs": [
        {"name": "IMAGE", "type": "IMAGE", "links": [17]}
      ],
      "properties": {}
    },
    {
      "id": 10,
      "type": "DenoiseCurveVisualizer",
      "pos": [850, 1000],
      "size": {"0": 315, "1": 100},
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {"name": "denoise_schedule", "type": "FLOAT_ARRAY", "link": 16}
      ],
      "outputs": [
        {"name": "schedule_plot", "type": "IMAGE", "links": [18]},
        {"name": "statistics", "type": "STRING", "links": [19]}
      ],
      "properties": {},
      "widgets_values": ["0"]
    },
    {
      "id": 11,
      "type": "LatentStatisticsMonitor",
      "pos": [1200, 1000],
      "size": {"0": 315, "1": 100},
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {"name": "latents", "type": "LATENT", "link": 15}
      ],
      "outputs": [
        {"name": "latents", "type": "LATENT", "links": null},
        {"name": "statistics", "type": "STRING", "links": [20]}
      ],
      "properties": {},
      "widgets_values": ["V2V Output"]
    },
    {
      "id": 12,
      "type": "ShowText",
      "pos": [1300, 1000],
      "size": {"0": 400, "1": 200},
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {"name": "text", "type": "STRING", "link": 14, "widget": {"name": "text"}}
      ],
      "outputs": [],
      "properties": {},
      "widgets_values": [""]
    },
    {
      "id": 13,
      "type": "PreviewImage",
      "pos": [1550, 250],
      "size": {"0": 400, "1": 400},
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {"name": "images", "type": "IMAGE", "link": 11}
      ],
      "properties": {}
    },
    {
      "id": 14,
      "type": "PreviewImage",
      "pos": [1650, 600],
      "size": {"0": 400, "1": 400},
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [
        {"name": "images", "type": "IMAGE", "link": 17}
      ],
      "properties": {}
    },
    {
      "id": 15,
      "type": "PreviewImage", 
      "pos": [1550, 1000],
      "size": {"0": 400, "1": 400},
      "flags": {},
      "order": 14,
      "mode": 0,
      "inputs": [
        {"name": "images", "type": "IMAGE", "link": 18}
      ],
      "properties": {}
    }
  ],
  "links": [
    [1, 1, 0, 3, 1, "IMAGE"],
    [2, 1, 0, 5, 0, "IMAGE"],
    [3, 2, 0, 3, 0, "CLIP"],
    [4, 3, 0, 6, 1, "CONDITIONING"],
    [5, 4, 0, 6, 0, "MODEL"],
    [6, 4, 2, 5, 1, "VAE"],
    [7, 5, 0, 6, 3, "LATENT"],
    [8, 6, 0, 7, 0, "LATENT"],
    [9, 7, 0, 8, 1, "IMAGE"],
    [10, 4, 2, 7, 1, "VAE"],
    [11, 7, 0, 13, 0, "IMAGE"],
    [12, 5, 0, 8, 0, "LATENT"],
    [13, 8, 0, 9, 0, "LATENT"],
    [14, 8, 2, 12, 0, "STRING"],
    [15, 8, 0, 11, 0, "LATENT"],
    [16, 8, 1, 10, 0, "FLOAT_ARRAY"],
    [17, 9, 0, 14, 0, "IMAGE"],
    [18, 10, 0, 15, 0, "IMAGE"],
    [19, 10, 1, null, 0, "STRING"],
    [20, 11, 1, null, 0, "STRING"]
  ],
  "groups": [
    {
      "title": "Qwen Image Editing",
      "bounding": [40, 30, 1520, 550],
      "color": "#3f789e"
    },
    {
      "title": "Keyframe V2V Processing",
      "bounding": [840, 580, 820, 400],
      "color": "#8A8"
    },
    {
      "title": "Technical Monitoring",
      "bounding": [840, 980, 750, 450],
      "color": "#A88"
    }
  ],
  "config": {},
  "extra": {
    "workflow_description": "Single image edit with technical V2V parameters. For actual video, you would need to: 1) Load video frames, 2) Select keyframes, 3) Edit each keyframe with Qwen, 4) Use MinimalKeyframeV2V to create denoise schedule, 5) Process with actual WAN V2V sampler (not included in this example as it requires WAN nodes)"
  },
  "version": 0.4
}