{
  "id": "qwen-vl-fixed-workflow",
  "revision": 0,
  "last_node_id": 120,
  "last_link_id": 230,
  "nodes": [
    {
      "id": 1,
      "type": "Note",
      "pos": [-400, -200],
      "size": [400, 150],
      "flags": {},
      "order": 0,
      "mode": 0,
      "properties": {},
      "widgets_values": [
        "FIXED QWEN2.5-VL WORKFLOW\n\nThis workflow uses the fixed nodes that:\n- Load Qwen2.5-VL via ComfyUI's CLIP loader\n- Use DiffSynth-Studio templates for consistency\n- Actually encode text (not random noise!)\n- Work with the diffusion pipeline"
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 37,
      "type": "UNETLoader",
      "pos": [20, 20],
      "size": [330, 90],
      "flags": {},
      "order": 1,
      "mode": 0,
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [196]
        }
      ],
      "properties": {
        "Node name for S&R": "UNETLoader"
      },
      "widgets_values": [
        "qwen_image_edit_fp8_e4m3fn.safetensors",
        "fp8_e4m3fn"
      ]
    },
    {
      "id": 39,
      "type": "VAELoader",
      "pos": [20, 340],
      "size": [330, 60],
      "flags": {},
      "order": 2,
      "mode": 0,
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [134, 167]
        }
      ],
      "properties": {
        "Node name for S&R": "VAELoader"
      },
      "widgets_values": [
        "qwen_image_vae.safetensors"
      ]
    },
    {
      "id": 66,
      "type": "ModelSamplingAuraFlow",
      "pos": [860, -145],
      "size": [300, 58],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 217
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [154]
        }
      ],
      "properties": {
        "Node name for S&R": "ModelSamplingAuraFlow"
      },
      "widgets_values": [3.5]
    },
    {
      "id": 73,
      "type": "LoraLoaderModelOnly",
      "pos": [395, 50],
      "size": [270, 82],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 196
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [217]
        }
      ],
      "properties": {
        "Node name for S&R": "LoraLoaderModelOnly"
      },
      "widgets_values": [
        "Qwen-Image-Lightning-4steps-V1.0.safetensors",
        1
      ]
    },
    {
      "id": 76,
      "type": "LoadImage",
      "pos": [20, 460],
      "size": [280, 320],
      "flags": {},
      "order": 3,
      "mode": 0,
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [194, 200]
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": [201]
        }
      ],
      "properties": {
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": [
        "view.png",
        "image"
      ]
    },
    {
      "id": 77,
      "type": "VAEEncode",
      "pos": [620, 680],
      "size": [140, 46],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [
        {
          "name": "pixels",
          "type": "IMAGE",
          "link": 202
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 134
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [209]
        }
      ],
      "properties": {
        "Node name for S&R": "VAEEncode"
      },
      "widgets_values": []
    },
    {
      "id": 80,
      "type": "ConditioningZeroOut",
      "pos": [600, 580],
      "size": [200, 26],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "conditioning",
          "type": "CONDITIONING",
          "link": 212
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [208]
        }
      ],
      "properties": {
        "Node name for S&R": "ConditioningZeroOut"
      },
      "widgets_values": []
    },
    {
      "id": 81,
      "type": "CFGNorm",
      "pos": [870, 15],
      "size": [270, 58],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 154
        }
      ],
      "outputs": [
        {
          "name": "patched_model",
          "type": "MODEL",
          "links": [206]
        }
      ],
      "properties": {
        "Node name for S&R": "CFGNorm"
      },
      "widgets_values": [1]
    },
    {
      "id": 84,
      "type": "VAEDecodeTiled",
      "pos": [1225, 760],
      "size": [210, 150],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 210
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 167
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [205]
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecodeTiled"
      },
      "widgets_values": [512, 64, 64, 8]
    },
    {
      "id": 106,
      "type": "ImageResizeKJv2",
      "pos": [130, 840],
      "size": [270, 340],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [
        {
          "name": "image",
          "type": "IMAGE",
          "link": 200
        },
        {
          "name": "mask",
          "type": "MASK",
          "link": 201
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [202]
        },
        {
          "name": "width",
          "type": "INT",
          "links": null
        },
        {
          "name": "height",
          "type": "INT",
          "links": null
        },
        {
          "name": "mask",
          "type": "MASK",
          "links": null
        }
      ],
      "properties": {
        "Node name for S&R": "ImageResizeKJv2"
      },
      "widgets_values": [
        1328,
        1328,
        "lanczos",
        "pad",
        "0, 0, 0",
        "center",
        2,
        "cpu"
      ]
    },
    {
      "id": 108,
      "type": "SaveImage",
      "pos": [1435, 155],
      "size": [270, 270],
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 205
        }
      ],
      "outputs": [],
      "properties": {
        "Node name for S&R": "SaveImage"
      },
      "widgets_values": ["qwen_vl_fixed"]
    },
    {
      "id": 109,
      "type": "KSampler",
      "pos": [875, 115],
      "size": [300, 556],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 206
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 213
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 208
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 209
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [210]
        }
      ],
      "properties": {
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        668523011998122,
        "randomize",
        4,
        1,
        "euler",
        "simple",
        1
      ]
    },
    {
      "id": 115,
      "type": "QwenVLCLIPLoader",
      "pos": [30, 180],
      "size": [270, 60],
      "flags": {},
      "order": 5,
      "mode": 0,
      "outputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "links": [219]
        }
      ],
      "title": "Qwen2.5-VL CLIP Loader (FIXED)",
      "properties": {
        "Node name for S&R": "QwenVLCLIPLoader"
      },
      "widgets_values": [
        "qwen_2.5_vl_7b.safetensors"
      ]
    },
    {
      "id": 120,
      "type": "QwenVLTextEncoder",
      "pos": [410, 250],
      "size": [400, 280],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 219
        },
        {
          "name": "edit_image",
          "type": "IMAGE",
          "link": 194
        }
      ],
      "outputs": [
        {
          "name": "conditioning",
          "type": "CONDITIONING",
          "links": [212, 213]
        }
      ],
      "title": "Qwen2.5-VL Text Encoder",
      "properties": {
        "Node name for S&R": "QwenVLTextEncoder"
      },
      "widgets_values": [
        "Transform the white coffee mug to float 20px above the wooden table's surface while maintaining its size and orientation, preserving all other elements in the kitchen scene.",
        "image_edit",
        true
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 112,
      "type": "Note",
      "pos": [850, 760],
      "size": [350, 200],
      "flags": {},
      "order": 14,
      "mode": 0,
      "properties": {},
      "widgets_values": [
        "KEY FIXES:\n\n1. QwenVLCLIPLoader uses ComfyUI's internal loader\n2. QwenVLTextEncoderFixed uses real encoding (not random!)\n3. DiffSynth-Studio templates for consistency\n4. Proper CLIP type for diffusion compatibility\n5. Vision tokens actually work!\n\nThis should produce proper images, not garbled output."
      ],
      "color": "#232",
      "bgcolor": "#353"
    }
  ],
  "links": [
    [134, 39, 0, 77, 1, "VAE"],
    [154, 66, 0, 81, 0, "MODEL"],
    [167, 39, 0, 84, 1, "VAE"],
    [194, 76, 0, 120, 1, "IMAGE"],
    [196, 37, 0, 73, 0, "MODEL"],
    [200, 76, 0, 106, 0, "IMAGE"],
    [201, 76, 1, 106, 1, "MASK"],
    [202, 106, 0, 77, 0, "IMAGE"],
    [205, 84, 0, 108, 0, "IMAGE"],
    [206, 81, 0, 109, 0, "MODEL"],
    [208, 80, 0, 109, 2, "CONDITIONING"],
    [209, 77, 0, 109, 3, "LATENT"],
    [210, 109, 0, 84, 0, "LATENT"],
    [212, 120, 0, 80, 0, "CONDITIONING"],
    [213, 120, 0, 109, 1, "CONDITIONING"],
    [217, 73, 0, 66, 0, "MODEL"],
    [219, 115, 0, 120, 0, "CLIP"]
  ],
  "groups": [
    {
      "id": 1,
      "title": "Step 1 - Load Models (FIXED)",
      "bounding": [10, -50, 370, 480],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 2,
      "title": "Step 2 - Image Preprocessing",
      "bounding": [10, 800, 400, 400],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 3,
      "title": "Step 3 - Text Encoding (FIXED)",
      "bounding": [380, 160, 450, 470],
      "color": "#a1309b",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 4,
      "title": "Step 4 - Generation Pipeline",
      "bounding": [850, -400, 600, 1100],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {},
  "version": 0.4
}