{
  "id": "2b232455-5c82-4c20-a0e8-71907d92a501",
  "revision": 0,
  "last_node_id": 167,
  "last_link_id": 362,
  "nodes": [
    {
      "id": 37,
      "type": "UNETLoader",
      "pos": [3.8020541667938232, 20.189966201782227],
      "size": [330, 90],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [276]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "UNETLoader",
        "models": [
          {
            "name": "qwen_image_fp8_e4m3fn.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_fp8_e4m3fn.safetensors",
            "directory": "diffusion_models"
          }
        ],
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.0.1",
          "widget_ue_connectable": {}
        }
      },
      "widgets_values": ["qwen_image_edit_fp8_e4m3fn.safetensors", "fp8_e4m3fn"]
    },
    {
      "id": 39,
      "type": "VAELoader",
      "pos": [-19.958463668823242, 314.6122131347656],
      "size": [330, 60],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "slot_index": 0,
          "links": [223, 244, 343, 355]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "VAELoader",
        "models": [
          {
            "name": "qwen_image_vae.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/vae/qwen_image_vae.safetensors",
            "directory": "vae"
          }
        ],
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.0.1",
          "widget_ue_connectable": {}
        }
      },
      "widgets_values": ["qwen_image_vae.safetensors"]
    },
    {
      "id": 66,
      "type": "ModelSamplingAuraFlow",
      "pos": [859.3681030273438, -144.76174926757812],
      "size": [300, 58],
      "flags": {},
      "order": 20,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 204
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [154]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "ModelSamplingAuraFlow",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.0.1",
          "widget_ue_connectable": {}
        }
      },
      "widgets_values": [3.5]
    },
    {
      "id": 73,
      "type": "LoraLoaderModelOnly",
      "pos": [394.9740905761719, 46.89153289794922],
      "size": [270, 82],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 276
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [170]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.49",
        "Node name for S&R": "LoraLoaderModelOnly",
        "models": [
          {
            "name": "Qwen-Image-Lightning-8steps-V1.0.safetensors",
            "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-8steps-V1.0.safetensors",
            "directory": "loras"
          }
        ],
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": ["Qwen-Image-Edit-Lightning-8steps-V1.0.safetensors", 1]
    },
    {
      "id": 80,
      "type": "ConditioningZeroOut",
      "pos": [599.8950805664062, 577.550537109375],
      "size": [197.712890625, 26],
      "flags": {},
      "order": 15,
      "mode": 0,
      "inputs": [
        {
          "name": "conditioning",
          "type": "CONDITIONING",
          "link": 248
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [271]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.50",
        "Node name for S&R": "ConditioningZeroOut",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": [],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 81,
      "type": "CFGNorm",
      "pos": [889.4481811523438, -33.180145263671875],
      "size": [270, 58],
      "flags": {},
      "order": 21,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 154
        }
      ],
      "outputs": [
        {
          "name": "patched_model",
          "type": "MODEL",
          "links": [269]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.50",
        "Node name for S&R": "CFGNorm",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": [1]
    },
    {
      "id": 86,
      "type": "PathchSageAttentionKJ",
      "pos": [608.7059936523438, -390.08392333984375],
      "size": [270, 58],
      "flags": {
        "collapsed": false
      },
      "order": 18,
      "mode": 4,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 162
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [169]
        }
      ],
      "title": "sage",
      "properties": {
        "cnr_id": "comfyui-kjnodes",
        "ver": "87d0cf42db7d59992daba4d58a83655b5b359f44",
        "Node name for S&R": "PathchSageAttentionKJ",
        "aux_id": "kijai/ComfyUI-KJNodes",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": ["auto"],
      "color": "#332922",
      "bgcolor": "#593930",
      "shape": 1
    },
    {
      "id": 87,
      "type": "CFGZeroStar",
      "pos": [1074.1048583984375, -349.59375],
      "size": [159.744140625, 26],
      "flags": {
        "collapsed": false
      },
      "order": 19,
      "mode": 4,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 169
        }
      ],
      "outputs": [
        {
          "name": "patched_model",
          "type": "MODEL",
          "links": [204]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.49",
        "Node name for S&R": "CFGZeroStar",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": [],
      "color": "#332922",
      "bgcolor": "#593930",
      "shape": 1
    },
    {
      "id": 88,
      "type": "TorchCompileModelQwenImage",
      "pos": [173.8088836669922, -312.2391357421875],
      "size": [282.74609375, 178],
      "flags": {
        "collapsed": false
      },
      "order": 14,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 170
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [162]
        }
      ],
      "properties": {
        "cnr_id": "comfyui-kjnodes",
        "ver": "876a6dd2929d88ec35c09c7cddc6c360f4b27013",
        "Node name for S&R": "TorchCompileModelQwenImage",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": ["inductor", false, "default", false, true, 128]
    },
    {
      "id": 116,
      "type": "VAEDecode",
      "pos": [1292.6866455078125, 532.370849609375],
      "size": [210, 46],
      "flags": {
        "collapsed": false
      },
      "order": 23,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 274
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 223
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [275]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "VAEDecode",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "version": "7.0.1",
          "widget_ue_connectable": {}
        }
      },
      "widgets_values": []
    },
    {
      "id": 120,
      "type": "QwenVLCLIPLoader",
      "pos": [35.810157775878906, 163.19113159179688],
      "size": [270, 60],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "links": [255, 341]
        }
      ],
      "title": "Qwen2.5-VL CLIP Loader (FIXED)",
      "properties": {
        "aux_id": "fblissjr/ComfyUI-QwenImageWanBridge",
        "Node name for S&R": "QwenVLCLIPLoader",
        "ver": "af23de074bc2fb8f41a0b621c12c020d636de558",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": ["qwen_2.5_vl_7b.safetensors"],
      "color": "#323",
      "bgcolor": "#535"
    },
    {
      "id": 124,
      "type": "TextEncodeQwenImageEdit",
      "pos": [2000.271728515625, 342.1376953125],
      "size": [400, 200],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 255
        },
        {
          "name": "vae",
          "shape": 7,
          "type": "VAE",
          "link": 244
        },
        {
          "name": "image",
          "shape": 7,
          "type": "IMAGE",
          "link": 359
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [248]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.52",
        "Node name for S&R": "TextEncodeQwenImageEdit",
        "ue_properties": {
          "widget_ue_connectable": {
            "prompt": true
          },
          "version": "7.0.1"
        }
      },
      "widgets_values": [""]
    },
    {
      "id": 131,
      "type": "KSampler",
      "pos": [939.9803466796875, 92.1950912475586],
      "size": [270, 526],
      "flags": {},
      "order": 22,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 269
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 345
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 271
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 358
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [274]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "KSampler",
        "ue_properties": {
          "widget_ue_connectable": {
            "seed": true,
            "steps": true,
            "cfg": true,
            "sampler_name": true,
            "scheduler": true,
            "denoise": true
          },
          "version": "7.0.1"
        }
      },
      "widgets_values": [
        407325260319073,
        "randomize",
        8,
        1,
        "euler",
        "simple",
        1
      ]
    },
    {
      "id": 132,
      "type": "SaveImage",
      "pos": [1306.1964111328125, -50.58351135253906],
      "size": [615.53125, 667.6171875],
      "flags": {},
      "order": 24,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 275
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.51",
        "Node name for S&R": "SaveImage",
        "ue_properties": {
          "widget_ue_connectable": {
            "filename_prefix": true
          },
          "version": "7.0.1"
        }
      },
      "widgets_values": ["qe_node"]
    },
    {
      "id": 144,
      "type": "ShowText|pysssss",
      "pos": [1716.4005126953125, 820.7736206054688],
      "size": [551.8046875, 376.109375],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "text",
          "type": "STRING",
          "link": 322
        }
      ],
      "outputs": [
        {
          "name": "STRING",
          "shape": 6,
          "type": "STRING",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfyui-custom-scripts",
        "ver": "1.2.5",
        "Node name for S&R": "ShowText|pysssss",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": [
        "<|im_start|>system\nDescribe the key features of the input image (color, shape, size, texture, objects, background), then explain how the user's text instruction should alter or modify the image. Generate a new image that meets the user's requirements while maintaining consistency with the original input where appropriate.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>Place the object from the left image into the scene in the right image.<|im_end|>\n<|im_start|>assistant\n"
      ]
    },
    {
      "id": 146,
      "type": "PreviewAny",
      "pos": [1800.7799072265625, 1326.7484130859375],
      "size": [464.60546875, 247.6640625],
      "flags": {},
      "order": 17,
      "mode": 0,
      "inputs": [
        {
          "name": "source",
          "type": "*",
          "link": 353
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.52",
        "Node name for S&R": "PreviewAny",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": []
    },
    {
      "id": 147,
      "type": "PreviewAny",
      "pos": [1010.5323486328125, 1388.4312744140625],
      "size": [210, 88],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "source",
          "type": "*",
          "link": 325
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.52",
        "Node name for S&R": "PreviewAny",
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.0.1"
        }
      },
      "widgets_values": []
    },
    {
      "id": 153,
      "type": "EmptyLatentImage",
      "pos": [2008.8819580078125, 146.8245086669922],
      "size": [270, 106],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [358]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.54",
        "Node name for S&R": "EmptyLatentImage",
        "ue_properties": {
          "widget_ue_connectable": {
            "width": true,
            "height": true,
            "batch_size": true
          },
          "version": "7.0.1"
        }
      },
      "widgets_values": [1024, 1024, 1]
    },
    {
      "id": 154,
      "type": "QwenTemplateBuilder",
      "pos": [732.420166015625, 732.378662109375],
      "size": [738.4408569335938, 415.07061767578125],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "formatted_prompt",
          "type": "STRING",
          "links": [322, 344]
        },
        {
          "name": "template_info",
          "type": "STRING",
          "links": []
        },
        {
          "name": "has_vision_tokens",
          "type": "BOOLEAN",
          "links": [325]
        }
      ],
      "properties": {
        "Node name for S&R": "QwenTemplateBuilder",
        "ue_properties": {
          "widget_ue_connectable": {
            "prompt": true,
            "template_preset": true,
            "system_prompt": true,
            "include_vision_tokens": true,
            "show_special_tokens": true
          },
          "version": "7.0.1"
        }
      },
      "widgets_values": [
        "Take the object from the left and place it in the scene on the right",
        "default_edit",
        "Describe the key features of the input image (color, shape, size, texture, objects, background), then explain how the user's text instruction should alter or modify the image. Generate a new image that meets the user's requirements while maintaining consistency with the original input where appropriate.",
        true,
        true
      ]
    },
    {
      "id": 160,
      "type": "QwenVLTextEncoder",
      "pos": [437.626708984375, 252.4956512451172],
      "size": [400, 316],
      "flags": {},
      "order": 16,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 341
        },
        {
          "name": "edit_image",
          "shape": 7,
          "type": "IMAGE",
          "link": null
        },
        {
          "name": "multi_reference",
          "shape": 7,
          "type": "QWEN_MULTI_REF",
          "link": 352
        },
        {
          "name": "vae",
          "shape": 7,
          "type": "VAE",
          "link": 343
        },
        {
          "name": "text",
          "type": "STRING",
          "widget": {
            "name": "text"
          },
          "link": 344
        }
      ],
      "outputs": [
        {
          "name": "conditioning",
          "type": "CONDITIONING",
          "links": [345]
        }
      ],
      "properties": {
        "Node name for S&R": "QwenVLTextEncoder",
        "ue_properties": {
          "widget_ue_connectable": {
            "text": true,
            "mode": true,
            "token_removal": true,
            "debug_mode": true,
            "optimize_resolution": true
          },
          "version": "7.0.1"
        }
      },
      "widgets_values": [
        "A beautiful landscape",
        "image_edit",
        true,
        "auto",
        true,
        true
      ]
    },
    {
      "id": 163,
      "type": "QwenMultiReferenceHandler",
      "pos": [607.0889892578125, 1288.75],
      "size": [270, 190],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "image1",
          "shape": 7,
          "type": "IMAGE",
          "link": 360
        },
        {
          "name": "image2",
          "shape": 7,
          "type": "IMAGE",
          "link": 362
        },
        {
          "name": "image3",
          "shape": 7,
          "type": "IMAGE",
          "link": null
        },
        {
          "name": "image4",
          "shape": 7,
          "type": "IMAGE",
          "link": null
        }
      ],
      "outputs": [
        {
          "name": "multi_reference",
          "type": "QWEN_MULTI_REF",
          "links": [352]
        },
        {
          "name": "preview",
          "type": "IMAGE",
          "links": [353]
        }
      ],
      "properties": {
        "Node name for S&R": "QwenMultiReferenceHandler"
      },
      "widgets_values": [
        "index",
        "1.0,1.0,1.0,1.0",
        "keep_proportion",
        "nearest-exact"
      ]
    },
    {
      "id": 164,
      "type": "VAEEncode",
      "pos": [2434.446044921875, 1220.5225830078125],
      "size": [140, 46],
      "flags": {},
      "order": 13,
      "mode": 4,
      "inputs": [
        {
          "name": "pixels",
          "type": "IMAGE",
          "link": 361
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 355
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": []
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.55",
        "Node name for S&R": "VAEEncode"
      }
    },
    {
      "id": 165,
      "type": "MarkdownNote",
      "pos": [-451.42816162109375, 503.6251220703125],
      "size": [662.10498046875, 556.1986694335938],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "# Multi-Reference Image Ordering and Spatial Interpretation\n\n## The Problem\n\nWhen using `concat` or `grid` methods with multiple reference images, Qwen interprets the combined image spatially:\n- **Left = First, Right = Second** (in concat mode)\n- **Top-Left = First, Top-Right = Second** (in grid mode)\n\nThis can cause confusion when your prompt says \"first image\" or \"second image\".\n\n## Understanding How Qwen Interprets Concatenated Images\n\n**Setup:**\n- image1: Coffee mug on table → Appears LEFT in concat\n- image2: Plush doll on rainbow → Appears RIGHT in concat\n- Method: concat creates: [Coffee Mug | Plush Doll]\n\n**Important:** In concat mode:\n- image1 = LEFT side = \"first image\" when referenced spatially\n- image2 = RIGHT side = \"second image\" when referenced spatially\n\n**Prompt Clarity Matters:**\n- Ambiguous: \"Place the object from the first image into the second image\"\n- Clear: \"Take the object from the left and place it in the scene on the right\"\n- Clearest: \"Put the coffee mug into the rainbow scene\"\n\n## Solutions\n\n### Option 1: Use `index` Method (Recommended)\nThe `index` method keeps images truly separate and handles positional references better:\n```\nMethod: index\nPrompt: \"Place the object from the first image into the scene of the second image\"\n```\n\n### Option 2: Adjust Your Prompt for Spatial Layout\nWhen using `concat`, refer to positions instead of order:\n```\nMethod: concat  \nPrompt: \"Place the object from the LEFT image into the scene from the RIGHT image\"\n```\n\n### Option 3: Swap Input Connections\nConnect your images in reverse order:\n- image1: Plush doll (will appear left)\n- image2: Coffee mug (will appear right)\n- Prompt: \"Place the object from the right into the left scene\"\n\n## Visual Layout Reference\n\n### Concat Method\n```\n[image1 | image2]\n LEFT     RIGHT\n```\n\n### Grid Method\n```\n[image1 | image2]\n[image3 | image4]\n\nTOP-LEFT  TOP-RIGHT\nBOT-LEFT  BOT-RIGHT\n```\n\n## Best Practices\n\n1. **For \"first/second\" references**: Use `index` method\n2. **For style transfer**: Use `offset` method with weights\n3. **For spatial comparison**: Use `concat` with left/right references\n4. **For multiple variations**: Use `grid` with corner references\n\n## Technical Details\n\nThe concatenation happens at the tensor level:\n- `concat`: `torch.cat(images, dim=2)` - Horizontal concatenation\n- `grid`: Creates 2x2 layout with images in reading order\n\nQwen's vision transformer processes images like text - left to right, top to bottom. This is why spatial position matters more than input order for concat/grid methods."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 166,
      "type": "LoadImage",
      "pos": [217.25112915039062, 711.3232421875],
      "size": [274.080078125, 314],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [359, 360, 361]
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.55",
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": ["IMG1.jpeg", "image"]
    },
    {
      "id": 167,
      "type": "LoadImage",
      "pos": [174.2808837890625, 1173.275634765625],
      "size": [274.080078125, 314],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [362]
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.55",
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": ["IMG2.jpeg", "image"]
    }
  ],
  "links": [
    [154, 66, 0, 81, 0, "MODEL"],
    [162, 88, 0, 86, 0, "MODEL"],
    [169, 86, 0, 87, 0, "MODEL"],
    [170, 73, 0, 88, 0, "MODEL"],
    [204, 87, 0, 66, 0, "MODEL"],
    [223, 39, 0, 116, 1, "VAE"],
    [244, 39, 0, 124, 1, "VAE"],
    [248, 124, 0, 80, 0, "CONDITIONING"],
    [255, 120, 0, 124, 0, "CLIP"],
    [269, 81, 0, 131, 0, "MODEL"],
    [271, 80, 0, 131, 2, "CONDITIONING"],
    [274, 131, 0, 116, 0, "LATENT"],
    [275, 116, 0, 132, 0, "IMAGE"],
    [276, 37, 0, 73, 0, "MODEL"],
    [322, 154, 0, 144, 0, "STRING"],
    [325, 154, 2, 147, 0, "*"],
    [341, 120, 0, 160, 0, "CLIP"],
    [343, 39, 0, 160, 3, "VAE"],
    [344, 154, 0, 160, 4, "STRING"],
    [345, 160, 0, 131, 1, "CONDITIONING"],
    [352, 163, 0, 160, 2, "QWEN_MULTI_REF"],
    [353, 163, 1, 146, 0, "*"],
    [355, 39, 0, 164, 1, "VAE"],
    [358, 153, 0, 131, 3, "LATENT"],
    [359, 166, 0, 124, 2, "IMAGE"],
    [360, 166, 0, 163, 0, "IMAGE"],
    [361, 166, 0, 164, 0, "IMAGE"],
    [362, 167, 0, 163, 1, "IMAGE"]
  ],
  "groups": [
    {
      "id": 1,
      "title": "Step1 - Load models",
      "bounding": [10, -20, 350, 433.6000061035156],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 3,
      "title": "Step3 - Prompt",
      "bounding": [380, 160, 450, 470],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 4,
      "title": "Lightx2v 8steps LoRA",
      "bounding": [383.0270690917969, -33.1086540222168, 450, 170],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.9318423366662651,
      "offset": [512.9038041295821, 126.51078513847413]
    },
    "frontendVersion": "1.25.11",
    "ue_links": [],
    "links_added_by_ue": [],
    "VHS_latentpreview": true,
    "VHS_latentpreviewrate": 0,
    "VHS_MetadataImage": true,
    "VHS_KeepIntermediate": true
  },
  "version": 0.4
}
